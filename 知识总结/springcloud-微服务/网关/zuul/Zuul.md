# Zuul

- **zuul是基于过滤器的网关。可以理解为就是拦截所有请求，通过过滤后，相eureka拿取服务进行请求，等待响应，进行响应过滤后返回值。所以过滤主要分三大类：服务前过滤，服务路由过滤，服务后响应过滤**

- 微服务架构下，服务的调用错综复杂，客户端的一个请求可能调用多个微服务。每个服务可能使用不同的语言进行编写，每台服务器上可能存在防火墙，或者是请求跨域预处理等等问题。那么每个客户端(主要是服务客户端)都需要维护多个服务地址，每个服务器我们需要单独配置防火墙，权限控制等等。所以我们可以对某一类服务，某一堆服务进行统一的管理和暴露，将他们交由一个统一的反向代理服务器进行代理，通俗说就是提供一个统一的入口。还可以理解成是一个路由器（我们通常通过路由器进访问外网，每个局域网的关口就被称为一个网关），通过它可以找到系统任意位置的服务。（服务路由-网关，服务发现-注册中心）
- 什么是Zuul是从设备和网站到应用程序后端的所有请求的前门。作为**边缘服务应用程序**，Zuul旨在实现动态路由，监视，弹性和安全性，Zuul包含了对请求的路由和过滤两个主要功能。
- Zuul是netflix开源的微服务网关，它可以和Eureka、Ribbon、Hystrix等组件配合使用。Zuul的核心是一系列的过滤器，这些过滤器可以完成一下功能
- 身份认证与安全：识别每个资源的验证要求，并拒绝那些与要求不符的请求
- 审查与监控：在边缘位置追踪有意义的数据和统计结果，从而带来精确的生产视图
- 动态路由：动态地将请求路由到不同地后端集群
- 压力测试：主键增加指向集群地流量，以了解性能
- 负载分配：未每一种负载类型分配对应容量，并启用超出限定值地请求
- 静态响应处理：在边缘位置直接建立部分响应，从而避免其转发到内部集群
- 多区域弹性：跨越AWSRegion进行请求路由，旨在实现ELB使用地多样化，以及让系统地边缘更贴切近系统地使用者。
- **总结：Zuul的两个主要功能：一个是路由器的功能就是动态路由（这里还隐藏了一个正向代理服务器的功能，你可以进行客户端行为预处理、限流等等），一个是系统反向代理服务器的功能-可以进行授权、身份验证。所以Zuul就是一个路由器和双向代理服务器的服务。**

# 什么是服务网关

- API网关，顾名思义，是出现在系统边界上的一个面向API的、串行集中式的强管控服务。这里的边界时企业IT系统的边界，可以理解为**企业级应用防火墙**，主要起到**隔离外部访问与内部系统**的作用。在微服务概念的流行之前，API网关就已经诞生了，例如银行、证券等领域常见的前置机系统，它也是解决访问认证、报文转换、访问统计等问题的。
- API网关的流行，源于近几年来移动应用与企业互联需求的兴起。移动应用、企业互联，使得后台服务支持的对象，从以前单一的Web应用，扩展到多种使用场景，且每种使用场景对后台服务的按要求都不尽相同。这不仅增加了后台服务的响应量，还增加了后台服务的复杂性。随着微服务架构的概念提出，API网关称为了微服务架构的一个标配组件。
- API网关时一个服务器，是系统对外的唯一入口。API网关封装了系统内部架构，为每个客户端提供定制的API。所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有非业务功能。API网关并不是微服务场景中必须的组件，如下图，不管有没有API网关，后端微服务都可以通过API很好地支持客户端地访问。
- 对于服务数量众多（关键是在分布式集群地场景中，因为每个服务地实例众多，分布范围广，对于服务客户端访问服务可以通过注册中心进行访问，不算太麻烦，但是对于用户客户端就比较麻烦了，因为IP可能经常变动，数量又庞大，如果要通过注册域名的方式解决，那么还是一种非常麻烦和耗费资源的事情。通过加一层来解决这个服务路由问题）、复杂度比较高、规模比较大的业务来说，引入API网关也有一系列的好处：
  - 聚合接口使得服务对调用者透明，客户端与后端的耦合度降低
  - 聚合后台服务，节省流量，提高性能，提升用户体验
  - 提供安全、流控、过滤、缓存、计费、监控等API管理功能
- 通过API网关可以将系统的某些服务组成一个逻辑上的局域网。

# 为什么要使用网关

- 单体应用：浏览器发起请i去到单体应用所在的及其，应用从数据库查询原路返回给浏览器，对于单体应用来说是不需要网关的。
- 微服务：微服务的应用可能部署在不同机房，不同地区，不同域名下。此时用户客户端想要请求对应的服务，都需要知道及其的具体IP或者域名URL，当微服务实例众多时，这是非常难以记忆的，对于客户端来说也它复杂难以维护。此时就有了网关，客户端相关的请求直接发送到网关，由**网关根据请求标识解析判断出具体的微服务地址**，**再把请求转发到微服务实例**。这其中的记忆功能就全部交给网关来操作。（如果说注册中心是系统内部的DNS、负载均衡是Nginx）
- 如果让客户端直接与各个微服务交互：
  - 客户端会多次请求不同的微服务，增加客户端的复杂性
  - 存在跨域请求，再一定场景下处理相对复杂
  - 身份认证问题，每个微服务需要独立身份认证
  - 难以重构，随着项目的迭代，可能需要重新划分微服务。
  - 某类服务的开、闭变得容易，只需要开闭网关入口即可。
  - 某些微服务可能使用了防火墙/浏览器不友好的协议，直接访问会由一定的困难
- 因此，我们需要网关介于客户端与服务器之间的中间层，所有外部请求率先经过微服务网关，客户端只需要与网关交互，只需要知道网关地址即可。这压根简化了开发且由以下优点：
  - 易于监控，可在微服务网关手机监控数据并其推送到外部系统进行分析。
  - 易于认证，可再微服务网关上进行认证，然后再将请i去转发到都断的微服务，从而无需再每个微服务中进行认证。
  - 减少了客户端与各个微服务之间的交互次数。

# 网关解决了什么问题

![20220510092603](.\img\20220510092603.jpg)

- 网关具有身份认证与安全、审查与监控、动态路由、负载均衡、缓存、请求分片与管理、静态响应处理等功能。当然最主要的职责还是外界联系。
  - 性能：API高可用，负载均衡，容错机制
  - 安全：权限身份认证、脱敏、流量清洗，后端签名（保证全链路可信调用），黑名单（非法调用限制）。
  - 日志：日志记录，一旦涉及分布式，全链路跟踪必不可少。
  - 缓存：数据缓存
  - 监控：记录请求响应数据，API耗时分析，性能监控
  - 限流：流量控制，错峰流控，可以定义多种限流规则
  - 灰度：线上灰度部署，可以减少风险。
  - 路由：动态路由规则。

# 常用网关解决方案

- Nginx+Lua

  - Nginx是由IgorSysoev为俄罗斯访问量第二的Rambler.ru站点开发的，一个高性能的HTTP和反向代理服务器。Nginx一方面可以**做反向代理，**一方面可以**做静态资源服务器。**

    - Nginx是C语言开发，而Zuul是Java语言开发
    - Nginx负载均衡实现，采用服务器实现负载均衡，而zuul负载均衡的实现是采用Ribbon+Eureka来实现本地负载均衡
    - Nginx适合于服务器端负载均衡，Zuul适合微服务中实现网关（也就是说Nginx是针对于具体的服务器进行流量负载，我们知道微服务并不依赖于服务器，而是单独的进程服务器，所以Nginx并不适用。而Zuul基于注册中心以及ribbon对服务流量进行计算，所以对于微服务架构更友好。）
      - **Nginx偏于硬件的负载，Zuul偏于逻辑负载。如果我们业务基于云部署，那么nginx不太适用。如果我们是自己搭建集群，并基本不会产生变化那么适用nginx.想想那么多微服务实例部署在各地还时常变化，nginx是很难管理的，对于静态的基本不变的还是挺好管理的**

    - nginx相比zuul功能会更加强大，因为nginx可以整合一些脚本语言（nginx+lua）

    - nginx是一个高性能的http和反向代理服务器，也是一个IMAP/POP3/SMIP服务器。Zuul是SpringCloudNetflix中的开源的一个API网关服务器，本质上是一个servlet应用，提供动态路由，监控，弹性，安全等边缘服务的框架。Zuul相当于是从设备和网站到应用程序都断的所有请求的前门。

      >Nginx适合做门户网关，是作为整个全局网关，对外的处于最外层的那种；而Zuul属于业务网关主要用来对应不同的客户端提供服务，用于聚合业务。各个微服务独立部署，职责单一，对外提供服务的时候需要有一个东西把业务聚合起来。
      >
      >Zuul可以实现熔断、重试等功能，这是nginx不具备的。
      >
      >

- Kong

  - kong 是Mashape提供的一款API管理软件，它本身是基于ngnix+lua的，但比nginx提供了更简单的配置方式，数据采用了ApacheCassandra/PostgreSQL存储，并且提供了一些优秀的插件，比如验证，日志，调用频次限制等。Kong非常诱人的地方就是提供了大量的插件来扩展因公用你给，通过设置不同的插件可以为服务提供各种增强的功能。

    >优点：基于nginx所以在性能你和稳定性上没有问题。空作为一款商业软件，在nginx上做了很扩展工作，而且还有很多付费的商业插件。kong本身也有付费的企业版。
    >
    >缺点：如果你适用SpringCloud，Kong如何结合目前已有的服务治理体系？

- Traefik

  - Traefik是一个开源的GO语言开发的为了让部署微服务更加便捷而诞生的现代http反向代理、负载均衡工具。它支持多种后台来自动化、动态的应用它的配置文件设置。Thraefik拥有一个基于angularjs编写的简单的往回走那姐买你，支持Rest API，配置文件热更新，无需重启进程，高可用集群模式等。**相对springcloud和kubernetes而言，比较适合后者**

- Spring Cloud Netflix Zuul

  - zuul是netflix公司开源的一个api网关组件，sprigcloud对其进行二次基于springboot的注解式封装做到开箱即用。目前来说，集合StringCloud提供的服务治理体系，可以做到请求转发，根据配或者默认的路由规则进行路由规则进行路由和LB，无缝集成Hystrix。

    >虽然通过自定义Filter实现我们想要的功能，但是由于Zuul本身的涉及式基于单线程的接收请求和转发处理，**是阻塞IO，不支持长连接。目前来看Zuul就显得很鸡肋。**2.x支持异步调用。SpringCloud
    >
    >推出自己的SpringCloudGateway.

- SpringCloud Gateway
  - SpringCloud Gateway作为SpringCloud生态系统中的网关，目标是代替Netflix Zuul，其不仅提供统一的路由方式，并且还基于Filter链的方式提供了网关基本的功能。目前最新版SpringCloud中引用的还是Zuul1.x，而这个版本**是基于过滤器的，是阻塞IO，不支持长连接。**
  
  - **spring cloud gateway 是基于spring生态系统之上构建的api网关，包括：spring5，springboot2和Project Reactor。spring cloud gateway旨在提供一种简单而有效的方法来路由到API，并为他们提供跨领域的关注点，例如：安全性，监视/指标，限流等。由于spring5支持Netty,http2，而springboot2支持spring5，因此springcloudgateway支持netty和http顺理成章**
  
  - **[HTTP2详解_张孟浩_jay的博客-CSDN博客_http2](https://blog.csdn.net/qq_40276626/article/details/120412462)**
  
  - **[什么是队头阻塞以及如何解决_欧阳惜竹的博客-CSDN博客_队头阻塞](https://blog.csdn.net/qq_37886086/article/details/109714173)**
  
    ![20220510141138](.\img\20220510141138.jpg)

# zuul网关配置

- 新建spring boot项目

- 因为zuul也是一个微服务，所以我们需要导入一个微服务的基本依赖以及zuul依赖。

- 配置服务基本参数：比如主机名、端口号

- 启动自动zuul装配类

- 配置动态路由规则，就是一组映射关系

  - 路由方式1通过具体的URL进行路由，要指定具体的地址且只能指定一个，很明显这个用的很少

  ![20220510143428](.\img\20220510143428.jpg)
  
  - 通过服务名称进行路由，这个就是依赖于注册中心的服务名称进行路由。IP由注册中心管理，网关只需要作为其中注册的一个微服务，然后像微服务之间进行调用一样拉取服务即可。
  
    - 所以配置先配置zuul的eureka客户端，注册为服务。
    - 然后配置服务名称的映射路由
  
    ![20220510144852](.\img\20220510144852.jpg)
  
  - 简化路由规则：即使通过服务名称进行路由注册，当服务十分庞大的情况下，在配置路由映射时工作量也十分庞大。所以我们可以采用约定大于配置。借助eureka与zuul整合后的默认路由映射。我们只要配置zuul的基本主机信息以及eureka客户端即可。
  
    **而其默认的配置方式其实就是服务路由的配置方式，服务名作为一个映射的开头，/服务名/\**作为虚拟路径，服务名作为实际路由到的服务**

# 路由排除

- 就是配置服务的哪些资源路径不能被用户进行访问。

- 我们可以通过路由排除设置不允许被访问的资源，允许被访问的资源可以通过路由规则进行设置

- 排除方式有两种

  - URL地址排除

    ```yaml
    #路由规则
    zuul:
    	ignored-patterns:/**/order/** #URL地址排除，排除所有包含/order/的路径
    	#不受路由排除影响
    	routes:
    		product-service: #路由id自定义
    			path: /product-service/** #配置请求url的映射路径
    			serviceId: product-service #根据serviceId自动从注册中心获取服务地址并转发请求
    ```

  - 服务名称排除

    ```yaml
    #路由规则
    zuul:
    	ignored-services: order-service #服务名称排除，多个服务逗号分割，“*”排除所有
    	#不受路由排除影响
    	routes:
    		product-service: #路由id自定义
    			path: /product-service/** #配置请求url的映射路径
    			serviceId: product-service #根据serviceId自动从注册中心获取服务地址并转发请求
    ```

# 路由前缀

- 通过配置路由前缀我们可以为虚拟路径统一加上前缀

```yaml
zuul:
	prefix:/api
```



# 网关过滤器

![20220510151942](.\img\20220510151942.jpg)

- zuul包含了对请求的路由和过滤两个核心功能，其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问系统的唯一入口的基础。而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验，服务聚合等功能的基础。然而实际上，路由功能在真正运行时，它的路由映射和请求抓发都是由几个不同的过滤器完成的。
- 路由映射主要通过pre类型的过滤器完成，它将请求路径与配置的路由规则进行匹配，以找到需要转发的目标地址；而请求转发的部分则是由routing类型的过滤器来完成，对pre类型过滤器获得的路由地址进行转发。所以说，过滤器可以说是zuul实现api网关功能最核心的不见，每一个进行zuul的http请求都会经过一系列的过滤器处理链得到请求响应并返回给客户端。
- 关键名词：
  - 类型：定义路由流程中应用过滤器的阶段，共pre、routing、post、error4个类型
  - 执行顺序：在同类型中，定义过滤器执行的顺序，比如多个pre类型的执行顺序。
  - 条件：执行过滤器所需的条件。true开启，false关闭。开闭过滤器。
  - 动作：如果符合条件，将执行的动作。具体操作。
- 过滤器类型
  - pre:请求被路由到原服务之前执行的过滤器
    - 身份认证
    - 选路由
    - 请求日志
  - routing：处理将请求发送到源服务器的过滤器
  - post：响应从源服务器返回时执行的过滤器
    - 对响应增加http头
    - 收集统计和度量指标
    - 将响应以流的凡是发送回客户端
  - error:上述阶段中出现错误时执行的过滤器

- 使用方法
  - 创建过滤器：springcloud netflix zuul中实现过滤器必须包含4个基本特征：过滤器类型，执行顺序，执行条件，动作（具体操作）。这些都是ZuulFilter抽象类中定义的4个抽象方法。所以要写一个过滤器需要先继承这个类。
  - 然后通过@Component将其托管到spring
- 通过spring容器获取请求
  - RequestContext.getCurrentContext();

#Zuul生命周期

![20220510185022](.\img\20220510185022.jpg)

# 网关过滤器异常统一处理

- 只需要写一个异常过滤器即可

- 因为zuul由一个自带的SendErrorFilter，所以需要将其关闭，我们自己写异常过滤器才会生效。禁用默认的异常过滤器。

  ```yaml
  zuul:
  	SendErrorFilter:
  		error:
  			disable: true
  ```

# Zuul整和Hystrix无缝整合

- 在SpringCloud中，Zuul启动器中包含了Hystrix相关依赖，在Zuul网关工程中，默认是提供了HystrixDashboard服务监控数据的。但是不会提供监控面板的界面展示，在Spring Cloud中，Zuul和Hystrix是无缝结合的。我们可以非常方便的实现网关容错处理。
- 为什么要通过网关来进行服务的降级、限流、熔断？

## 网关监控

- Zuul的依赖中包含了Hystrix的相关jar包，所以我们不需要在项目中额外添加Hystrix的依赖。但是需要开启数据监控的项目中要添加dashboard依赖

- 然后再配置文件种开启hystrix.stream端点

  ```yaml
  #度量指标监控和健康检查
  management:
  	endpoints:
  		web:
  			exposure:
  				include: hystrix.stream
  ```

- 启用监控

  - @EnableZuulProxy
  - @EnableHystrixDashboard

- http://localhost:9000/hystrix查看监控中心界面

## 网关熔断

- 在edgware版本之前，Zuul提供了接口ZuulFallbackProvider用于实现fallback处理。从Edgware版本开始，Zuul提供了接口FallbackProvider来提供fallback处理。

- **Zuul的fallback容错处理逻辑，*只针对timeout异常处理*，当请求被Zuul路由后，只要服务有返回（包括异常），都不会触发Zuul的fallback容错逻辑。**

  - **注意zuul默认调用服务的响应时间为1s**
  - 是否还会对网关本身的异常产生时进行返回？
    - 具体不清楚。但是网关本身的异常是通过error过滤器进行返回的，所以应该不会。

  >因为对于Zuul网关来说，做请求路由分发的时候，结果由远程服务运算。远程服务反馈了异常信息，Zuul网关不会处理异常，因为无法确定这个错误是否是应用程序真实想要反馈给客户端的。

- 使用Zuul的网关熔断

  - 创建一个类实现FallbackProvider接口并重写其中的方法，并将其托管给spring（@Component）。

    ![20220510200435](.\img\20220510200435.jpg)

    ![20220510200601](.\img\20220510200601-16521844246241.jpg)

    ![20220510200804](.\img\20220510200804.jpg)

    ![20220510200859](.\img\20220510200859.jpg)

    ![20220510200956](.\img\20220510200956.jpg)

## 网关限流

- 顾名思义，限流就是限制流量，就像你宽带包有1个G的流量，用完了就没了。通过限流，我们可以很好的控制系统的QPS，从而达到保护系统的目的。Zuul网关组件也提供了限流保护。当请求并发达到阈值，自动促发限流保护，返回错误结果。只要提供error错误处理机制即可。
  - 就像hystrix的熔断器，当到达某个条件时直接返回服务降级的逻辑。这里就是当流量到达上限时，直接返回错误结果,只不过这个是用的fallback返回。
- 为什么需要限流？
  - 比如Web服务，对外API，这种类型的服务有以下几种可能导致及其被拖垮：
    - 用户增长过快
    - 因为某个热点事件（微博热搜）
    - 竞争对象爬虫
    - 恶意的请求
  - 这些情况都是无法预知的，不知道什么时候回有10倍甚至20倍流量打进来，如果真碰上这种情况，扩容时根本来不及的。

### 限流算法之计数器算法

- 常见的限流算法：

  - **[几种常见的限流算法 - zhqqqy - 博客园 (cnblogs.com)](https://www.cnblogs.com/geeko/p/16020359.html)**
  - 计数器算法
  - 固定窗口算法
  - 滑动窗口算法
  - 漏桶（Leaky Buket）算法
  - 令牌桶（Token Bucket）算法：zuul的限流是基于第三方组件rightlimit实现，而其又是基于令牌桶算法实现的。
  - **注意限流的目的一是为了保护系统，二是限制系统的总使用量，前者应该主要是限制小时间段的并发量，后者应该是限制长时间端的请求数量**
  - **我们应该主要考虑的是系统的并发量**

- 计数器算法：通常用于并发稳定的情况下的总量限制

  - 计数器算法是限流算法里最简单也是最容易实现的一种算法，比如我们规定们对于A接口来说，我们1分钟的访问次数不能超过100个。那么我们可以这么做：在一开始的时候，我们可以设置一个计数器（比如用JUC中信号量，计数阀），每当一个请求过来的时候，计数器就加1，如果计数器的值大于100并且该请求的间隔时间还在1分钟之内，触发限流；如果该请求与第一个请求的间隔时间大于1分钟，重置计数器重新计数。
  - 明显这个算法缺点就是只是限制了长时间段的总QPS，而没有并发QPS，那么意味着在某个瞬间大量请求可能会超过服务的负载，将服务进行击穿，从而宕机。
  - 这个算法虽然简单，但是有一个十分致命的问题，那就是临界问题。就是我们上面的描述。还有一个问题就是：**资源浪费问题，我们希望的是请求均匀分散在时间段内，如果请求不均匀化，那么可能有的时间段系统紧急，有的时间段系统空闲，资源浪费。**
    - 总之就是太死板，没有灵活性，不能面对突发情况，资源浪费现象无论什么算法必然存在，因为只要空闲必然浪费，只是浪费严重与否。所以需要考虑服务器本身的处理能力。
  
- 漏桶算法

  - 漏桶算法粗略的认为就是注水漏水的过程，固定的桶容量，以一定速率进行加水，一定速率进行放水，当水超过桶容量时就抛弃。

    - 具体到网关限流：就是我们需要准备一个参数限制当前网关的请求量（准确说应该是限制tomcat的接收量），然后网关以一定的速率将请求转发给具体服务实例。**一般用户发送请求的速率不是我们能控制的，也不应该控制**。如果容量已经满了，网关直接就抛弃请求或者返回一个兜底响应（往往会将压力转到网关，因为如果并发量很大，那么网关需要进行大量的IO响应，同样会堆积大量的请求）。

  - 优缺点分析：

    - 优点：将流量控制在网关层，不向下流蔓延，危险即时控制。

    - 缺点：网关需要比较准确的估计下层服务承载能力，这样才能知道大致的输出速率，保证服务既不会倍被压垮，又不会空闲。

      **假如说并没有设置合理的转发速率，那么会产生的影响：速率太小，请求堆积在网关，网关崩塌，下层服务空闲。速率过大，下层无法承受，限流失效。**

  - 漏桶算法主要用途是在于保护他人（服务实例），假设注入水量很大，而出水量较慢，则会造成网关的资源堆积可能大致网关瘫痪。而目标服务可能是可以处理大量请求的，但是漏桶算法出水量缓慢反而造成服务的资源浪费。

  - 漏桶算法无法应对突发调用，不管上面流量多大，下面留出的速度始终保持不变。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来的及处理的请求就先放在桶里，桶肯定是由容量上限，如果桶满了，那么新进来的请求就会丢弃。

    - 难以理解的是这个不就是当突发时抛弃请求，只要保证我们流出的速度是下层服务处理能力的最大值或者近似最大值不就行了？

- 令牌桶算法

  - 令牌桶算法是对漏桶算法的一种改进，漏桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定速率往桶中放令牌。每次请求调用需先获取令牌，只有拿到令牌，才有机会继续执行，否则选择等待可用的令牌、或者直接拒绝。放令牌这个动作是持续不断的进行，如果桶中令牌数到达上限，就丢弃令牌。

    >大致场景：桶中一直由大量的可用令牌，这时进来的请求可以直接拿到令牌执行，比如设置QPS为100/s,那么限流器初始化完成一秒后，桶中就已经有100个令牌了，等服务启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求，当桶中没有令牌时，请求会进行等待，最后相当于以一定的速率执行。

  - spring cloud gateway内部使用的就是该算法，大致描述如下：

    - 所有的请求在处理之前都需要拿到一个可用的令牌才会被处理

    - 根据限流的大小，设置按照一定的速率往桶中添加令牌

    - 桶设置最大的放置令牌限制，当桶满时、新添加的令牌就被丢弃或者拒绝

    - 请求到达后首先要获取令牌桶中的令牌，拿着令牌才可以进行其他的业务逻辑，处理完业务逻辑之后，将令牌直接删除

    - 令牌桶有最低限额，当桶中的令牌到达最低限额的时候，请求处理完之后将不会删除令牌，以此保证足够的限流。

      ![20220511180831](.\img\20220511180831.jpg)

    - 令牌桶算法和漏桶算法都是基于队列实现。

## Zuul局部限流配置

- 使用局部限流配置，Zuul仅针对对配置的服务提供限流保护

- 注意限流依赖于缓存

-  [Zuul实现限流 - 灰信网（软件开发博客聚合） (freesion.com)](https://www.freesion.com/article/2750755711/)

  ```xml
  	<dependency>
          <groupId>com.marcosbarbero.cloud</groupId>
          <artifactId>spring-cloud-zuul-ratelimit</artifactId>
          <version>2.0.0.RELEASE</version>
      </dependency>
  ```

  ```yaml
  zuul:
  	#服务器限流
  	ratelimit:
  		#开启限流保护
  		enabled:true
  		#限流数据存储方式
  		repository:REDIS
  		#policy-list 自定义配置，局部生效
  		policy-list:
  			#指定需要被限流的服务名称
  			order-service:
  				- limit: 5
  					refresh-interval: 60 #60s内请求超过5次，服务端会抛出异常，60s后可以恢复正常请求
  					type:
  						- origin
  						- url
  						- user
  ```

- 注意，当第一次请求开始时就已经开始限流计时和计数。

##自定义限流策略

- 如果希望自己控制限流策略，可以通过自定义**RateLimitKeyGenerator**的实现来增加自己的策略逻辑。定义一个类实现这个接口即可。通常是继承DefalutRateLimitKeyGenerator然后将这个类注册到spring中，可以通过@Componet或者通过配置类注册。

  ![20220511193706](.\img\20220511193706.jpg)

  - 对请求方式进行限流

## 网关限流错误处理

- 就是当发生限流后，网关服务端是会抛出一个Too+MANY_REQUESTS异常。所以是网关本身的异常错误，所以可以用我们前面说的error过滤器进行设置返回值。

## 网关调优

![20220511200016](.\img\20220511200016.jpg)

- 从上图可以看出，整体的请求逻辑还是比较复杂的，在没有Zuul网关的情况下，client请求service的时候，也有请求超时的可能。那么当增加了Zuul网关的时候，请求超时的可能就更明显了
- 当请求哦那个过Zuul网关路由到服务，并等待服务返回响应，这个过程中Zuul也有超时控制。Zuul的底层使用的是Hystrix+ribbon来实现请求路由。

![20220511200623](.\img\20220511200623.jpg)

- Zuul中的Hystrix内部使用线程池隔离机制提供请求路由实现，其默认的超时时长为1000ms。ribbon底层默认超时时长为5000ms。如果Hystrix超时，直接返回超时异常。如果Ribbon超时，同时Hystrix为超时，Ribbon会自动进行服务集群轮询重试，知道Hystrix超时为止。如果Hystrix超时时长小于Ribbon超时时长，Ribbon不会进行服务集群轮询重试。

  - 主要明白Hystrix的作用是统一的异常处理，防止扇出。Ribbon是进行负载均衡计算。
  - 那么Ribbon如果负载计算调用某个服务实例失败后，不要立即产生熔断返回，因为可能存在其他可用服务，或者服务只是网络延时，重试一下就能成功。**就是为了保证高可用，所以Ribbon的超时最好小于Hystrix**

- 添加retry依赖

  ```xml
  spring-retry
  ```

  

- 配置超时以及开启重试

![20220511202754](.\img\20220511202754.jpg)

- 然后要开启重试：@EnableRetry

#Zuul与Sentinel整合

- sentinel支持对spring cloud gateway、netfilx zuul等主流的API Gateway 进行限流。

  ![20220511204625](.\img\20220511204625.jpg)

- https://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel
- [2021最新版-SpringCloud-微服务-Zuul服务网关框架搭建-通俗易懂附配套资料_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1m64y1W7es?p=29&spm_id_from=pageDriver)

## 自定义限流处理（网关熔断）

- 发生限流错误之后的处理流程：
  - 发生限流之后可自定义返回参数，通过实现ZuulBlockFallbackProvider接口，默认的实现是DefalutBlockFallbackProvider
  - 默认的fallback route的规则是routeID或自定义的API分组名称
- 就是将zuul的error改为了通过fallback形式进行返回。本质上还是使用的过滤器，Sentinel只是进行将它封装了一下，变成了fallback形式。

# 高可用网关

- [2021最新版-SpringCloud-微服务-Zuul服务网关框架搭建-通俗易懂附配套资料_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1m64y1W7es?p=31&spm_id_from=pageDriver)

- 就是要将网关服务进行集群处理。

- 业内通常用多少个9来衡量网站的可用习惯，例如QQ的可用性是4个9，就是说QQ能够保证在一年里，服务在99.99%的时间是可用的，只有0.01%时间不可用，大约最多53分钟。
- 对于大多网站而言，2个9是基本可用，3个9是叫高可用，4个9是拥有自动恢复能力的高可用。
- 实现高可用的主要手段是数据的浓郁备份和服务失效的转移，这两种手段具体可以怎么做呢，在网关里如何体现？主要有以下几个方向：
  - 集群部署
  - 负载均衡
  - 健康检查
  - 节点自动重启
  - 熔断
  - 服务降级
  - 接口重试
- Nginx+网关集群实现高可用网关
  - 搭建服务网关集群，然后让nginx作为服务网关的网关。**因为Ribbon负载均衡仅仅只是对被调用服务进行负载，也就是说网关本身实际上我们是没有进行负载均衡的，hystrix也是如此，如果要使用就必须要配置一个网关客户端。这里我们使用Nginx实现对网关的负载均衡。**
  - 一个请求过来，首先经过Nginx的一层负载，到达网关，然后由网关负载到真实后端，若后端由问题，网关会进行重试访问，**多次访问后人返回失败，可以通过熔断或服务降级立即返回结果。（就是超时会自动熔断）**而且，由于负载均衡，网关重试时，不一定会访问到出错的后端。
