# 深度学习

## 1、基础知识

### 1.1tensorflow框架

- [TensorFlow官方文档_w3cschool](https://www.w3cschool.cn/tensorflow_python/)
- [win10环境下使用python安装tensorflow - 程嘿嘿 - 博客园 (cnblogs.com)](https://www.cnblogs.com/cff2121/p/11782357.html)
- 概述：
  - 基本思想
    - 在tensor类上定义函数，通过graph类自动求导
    - Graph包含placeholdersX和Y,以及W和B的变量，所有的数学操作、损失函数、优化过程。运行时，所有数据赋给Graph，将数据批量传入placeholders，运行Graph。
    - Graph的每个节点可以通过网络相互连接，并且可以并行运行。
  - 主要构成：
    - Graph
      - 节点：Operation(操作单元)
      - 边：Tensor（在节点之间流动的tensor-张量）
    - Session
      - 可在CPU，GPU上运行
      - 运行过程
        - 输入
          - Feches：一个graph节点的列表，返回这些节点的输出
          - Feeds：将graph节点通过字典形式映射为具体的值，明确给定字典的每个graph节点的值
    - Variables
      - 输出当前值的状态节点，在一个图里的多种执行过程中会保留状态
      - 共享
        - tf get_variables
        - tf variable_scope
    - Placeholders:在执行是才需要被填充数据的节点，例如输入Inputs、特征Features、标准Labels等
  - 执行过程
    - 构建过程
      - 创建一个计算图Graph
      - 惰性计算：运行时才会求值
      - 所有的计算节点都会添加到默认图
    - 执行过程
      - 通过session来计算graph中的operation
      - 声明的变量在取值之前必须先初始化
      - 训练模型时使用变量来存放并更新所有的参数，变量是包含了tensor的**内存缓存区**
  - 与NUMPY的对比：惰性计算、自动求导，需要构建一个计算图Graph，在Session里运行
- 高级API：
  - TF Learn(tf.contrib.learn):类似于scikit-learn的接口
  - TF SLIM：一个可以定义，训练，和评估的复杂的模型的轻量库。
  - Kears等



### 1.2机器学习或是深度学习的的项目流程

- 数据预处理:一种数据挖掘方法，本质就是为了将原始数据转换为可以理解的格式或者符合我们挖掘的格式。
  - 主要步骤
    - 数据清洗： 填写缺失的值，光滑噪声数据，识别或删除离群点，并解决不一致性来“清理数据”；
    - 数据集成：使用多个数据库，数据立方体或文件；
    - 数据归约： 用替代的，较小的数据表示形式替换元数据，得到信息内容的损失最小化，方法包括维规约，数量规约和数据压缩；
    - 数据变换：将数据变换成使用挖掘的形式。
- 模型训练
- 模型保存
- 模型预测
- 总结：（也就是我们还会建立一个初始模型，然后使用大量的数据对模型进行训练（我猜：应该是计算输入得到实际的输出然后比对预期的输出，如果之间的误差合法则通过，但是这个预期输出是怎么确定？），在训练过程中我们会不断的修正我们的模型，直到这个模型达到我们标准，就将这个模型保存起来，然后我们就能通过这个模型对外界的输入进行预测）

### 1.3Tensorflow的快速入门

#### 1.3.1学习要点

- 数据类型
- 运行机制
- 数据的IO
- 模型的训练
- 模型保存
- 模型的调用

#### 1.3.2编写Tensorflow的两个步骤

- 构建计算图graph
- 使用session区执行graph中的operation

#### 1.3.3Tensorflow的基本概念

- tensorflow的设计思想就是根据数据流图来的，想象成一张数据流图就行。所以边代表数据，而节点代表的是处理数据的操作（不要理解为普通的图数据结构模型）

- Tensor：类型化的多维数组，图的边（类似邻接矩阵）（想想神经网络就是一张错综复杂的图，而信号或者数据就通过这些边在节点上流动）

  - [笔记 | 什么是张量（tensor）& 深度学习 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/48982978)

  - tensor=a object that is invariant under a change of coordinates and components that change  in the speacial,predictable way under a change of coordinate（在坐标变化下不变的物体和在坐标变化下以特殊的、可预测的方式变化的组件）

  - tensor=a collection of vecotr and covectors combined together using the tensor product（用张量积将向量和协向量组合在一起的集合）

  - tensor创建方法

    <img src="\图片\20211126224448.jpg" style="zoom:50%;" />

  - tensor属性

    - rank（与线性代数中的秩不同）:rank一般是指数据的维度（点、线、面、单点立体、面立体、空间立体）

    - Shape:**指tensor每个维度数据的个数**，可以用python的list/tuple表示。

      <img src="图片\20211127095819.jpg" style="zoom:90%;" />

  - Data_type:是指单个数据的类型。常用DT_FLOAT,也就是32的浮点数。下图表示了所有的types。（从这些type可见，深度学习处理的数据就是各式各样的数值计算）

    <img src="图片\20211127100437.jpg" style="zoom:80%;" />

- Operation：执行计算的单元，图的节点

  - 一个符号化的运算过程

  - Graph中的计算节点

  - 输入输出均为Tensor

  - 创建方法：[tensorflow之常用函数（tf.Constant） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/78426564)

    ![](图片\20211127101012.jpg)

    意思是：创建了一个[[1],[1,1]]的tensor x,一个[[2],[2,2]]tensor y,然后执行add操作得到tensor z。

- Graph:一张有边与点的图，其表示了需要进行计算的任务

  - Tensorflow中使用Graph表示可计算的图。图是由操作Operation以及张良Tensor来构成，其中Operation表示图的节点（即计算单元），而Tensor则表示图的边（即Operation之间流动的数据单元）。
  - **注意要点**
    - (python中)tensorflow中始终存在一个默认的graph，如果定义了多个图，需要as_default()方法将图设置为一个默认图，这样tf中调用创建的tensor、operation才能添加到图中。
    - <img src="图片\20211127103536.jpg" style="zoom:80%;" />
    - 当session执行graph时，图中的节点并不一定都会执行，只会执行需要的路径上的节点操作。

- Session：称之为会话的上下文，用于执行图。（类似线程）

  - 提供了Operation执行和Tensor求值环境。

- Variables：

  - 作用：保存和更新参数（训练模型时，使用这个类来保存和更新参数）。每个tensor一旦有了明确的Variables的指向，数据就不会丢失，且可以通过sever保存在磁盘上。

  - 使用前必须初始化、可共享

  - 定义：

    ```python
    #创建权重
    weights=tf.Variable(tf.random_normal([784,200],stddev=0.35),name="weights")
    #tf.random_normal表示随机生成一个正态分布的tensor
    #j
    biases=tf.Variable(tf.zeros([200],name="biases"))
    ```

    

